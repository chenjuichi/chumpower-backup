import os
import datetime
import pathlib
import csv
import time
import shutil
import psutil
import glob
import math

import pymysql
from sqlalchemy import exc
from sqlalchemy import exists

import re

import pandas as pd
import openpyxl
from openpyxl import Workbook, load_workbook
from openpyxl.styles import Font, Alignment, PatternFill
from database.tables import User, Session, Material, Bom, Assemble, Product
from database.p_tables import P_Material, P_Bom, P_Assemble, P_Product

from database.tables import ProcessedFile
from flask import Blueprint, jsonify, request, current_app

import warnings
warnings.filterwarnings(
   "ignore",
   category=FutureWarning,
  message=".*Setting an item of incompatible dtype.*"
)

excelTable = Blueprint('excelTable', __name__)

from log_util import setup_logger
logger = setup_logger(__name__)                 # æ¯å€‹æ¨¡çµ„ç”¨è‡ªå·±çš„åç¨±


# ------------------------------------------------------------------


def read_all_excel_process_code_p():
    """
    å¾ _server_dir ç›®éŒ„è£¡çš„ Excel æª”æ¡ˆï¼ˆåªè™•ç† .xlsx/.xlsmï¼‰ï¼Œ
    è®€å–å·¥ä½œè¡¨ã€Œé…ä»¶å·¥ä½œä¸­å¿ƒè³‡æ–™è¡¨-0922 (2)ã€ä¸­
    æ¬„ä½ã€Œè£½ç¨‹ä»£è™Ÿ \n(æ¨™æº–å…§æ–‡ç¢¼)ã€çš„å…§å®¹ï¼Œ

    è‹¥è©²æ¬„ä½å…±æœ‰ m ç­†æœ‰æ•ˆè³‡æ–™ï¼š
      ç¬¬ 1 åˆ— -> m
      ç¬¬ 2 åˆ— -> m-1
      ...
      ç¬¬ m åˆ— -> 1

    ç”¢ç”Ÿä¸¦å›å‚³ code_to_assembleStep = { '100-01': m, '100-02': m-1, ... }
    ï¼ˆæ³¨æ„ï¼šé€™è£¡æœƒæŠŠå‰é¢çš„ 'B' å»æ‰ï¼Œå› ç‚ºå¾Œé¢ä½ æœ‰ code = workNum[1:]ï¼‰
    """

    _base_dir = current_app.config['baseDir']
    _server_dir = _base_dir.replace("excel_in", "server")

    #print("read_all_excel_process_code_p(), _base_dir:", _base_dir)
    #print("read_all_excel_process_code_p(), _server_dir:", _server_dir)

    code_to_assembleStep = {}

    target_sheet_name = "é…ä»¶å·¥ä½œä¸­å¿ƒè³‡æ–™è¡¨-0922 (2)"
    # å¯èƒ½çš„æ¬„ä½åç¨±
    target_col_candidates = [
        "è£½ç¨‹ä»£è™Ÿ \n(æ¨™æº–å…§æ–‡ç¢¼)",
        "è£½ç¨‹ä»£è™Ÿ (æ¨™æº–å…§æ–‡ç¢¼)",
    ]

    # åªæƒæ openpyxl æ”¯æ´çš„æ ¼å¼
    valid_exts = (".xlsx", ".xlsm", ".xltx", ".xltm")

    for root, dirs, files in os.walk(_server_dir):
        for fname in files:
            lower = fname.lower()

            # 1) å…ˆéæ¿¾æ‰é Excel æª”æ¡ˆï¼ˆä¸å†å»é–‹ .bat / .pyï¼‰
            if not lower.endswith(valid_exts) and not lower.endswith(".xls"):
                continue

            full_path = os.path.join(root, fname)
            #print(f"è™•ç† Excel æª”æ¡ˆ: {full_path}")

            # 2) .xls ç›´æ¥æç¤ºï¼šopenpyxl ä¸æ”¯æ´ï¼Œè¦ä½ æ”¹æˆ .xlsx
            if lower.endswith(".xls"):
                print(f"  æª”æ¡ˆ {fname} ç‚ºèˆŠç‰ˆ .xlsï¼Œopenpyxl ä¸æ”¯æ´ï¼Œè«‹å¦å­˜ç‚º .xlsx å¾Œå†ä½¿ç”¨ã€‚")
                continue

            # 3) å…¶ä»–å‰¯æª”åï¼ˆ.xlsx/.xlsmâ€¦ï¼‰æ‰ç”¨ openpyxl è®€
            try:
                wb = load_workbook(full_path, data_only=True)
            except Exception as e:
                print(f"  è¼‰å…¥å·¥ä½œç°¿å¤±æ•—: {e}")
                continue

            if target_sheet_name not in wb.sheetnames:
                print(f"  æª”æ¡ˆ {fname} æ²’æœ‰å·¥ä½œè¡¨ã€Œ{target_sheet_name}ã€ï¼Œç•¥éã€‚")
                continue

            ws = wb[target_sheet_name]

            # è®€ç¬¬ä¸€åˆ—ç•¶è¡¨é ­
            header_row = next(ws.iter_rows(min_row=1, max_row=1, values_only=True), None)
            if not header_row:
                print(f"  æª”æ¡ˆ {fname} çš„è¡¨é ­æ˜¯ç©ºçš„ï¼Œç•¥éã€‚")
                continue

            # æ‰¾ç›®æ¨™æ¬„ä½çš„ column indexï¼ˆ1-basedï¼‰
            target_col_idx = None

            # å…ˆç›´æ¥æ¯”å°å€™é¸åç¨±
            for idx, val in enumerate(header_row, start=1):
                if val is None:
                    continue
                val_str = str(val).strip()
                if val_str in target_col_candidates:
                    target_col_idx = idx
                    break

            # æ‰¾ä¸åˆ°å°±æ¨¡ç³Šæœå°‹ã€Œè£½ç¨‹ä»£è™Ÿã€
            if target_col_idx is None:
                for idx, val in enumerate(header_row, start=1):
                    if val is None:
                        continue
                    val_str = str(val).strip()
                    if "è£½ç¨‹ä»£è™Ÿ" in val_str:
                        target_col_idx = idx
                        print(f"  ç™¼ç¾ç›¸ä¼¼æ¬„ä½åç¨±ä½¿ç”¨: {val_str} (col {idx})")
                        break

            if target_col_idx is None:
                print(f"  æª”æ¡ˆ {fname} æ‰¾ä¸åˆ°ã€Œè£½ç¨‹ä»£è™Ÿã€æ¬„ä½ï¼Œç•¥éã€‚è¡¨é ­: {list(header_row)}")
                continue

            # å–å‡ºè©²æ¬„ä½å¾ç¬¬2åˆ—é–‹å§‹çš„æ‰€æœ‰éç©ºå€¼
            codes = []
            for row in ws.iter_rows(min_row=2, values_only=True):
                if target_col_idx - 1 >= len(row):
                    continue
                cell_val = row[target_col_idx - 1]
                if cell_val is None:
                    continue
                cell_str = str(cell_val).strip()
                if cell_str == "":
                    continue

                # ğŸ”´ é‡é»ï¼šé€™è£¡çµ±ä¸€æŠŠå‰é¢çš„ 'B' å»æ‰ï¼Œè®“ key è®Šæˆ '100-01'
                # é€™æ¨£æ‰èƒ½å°ä¸Š read_all_excel_files_p è£¡çš„ code = workNum[1:]
                if cell_str.startswith("B"):
                    cell_str = cell_str[1:]

                codes.append(cell_str)

            if not codes:
                print(f"  æª”æ¡ˆ {fname} çš„ç›®æ¨™æ¬„ä½æ²’æœ‰æœ‰æ•ˆè³‡æ–™ï¼Œç•¥éã€‚")
                continue

            m = len(codes)
            print(f"  æª”æ¡ˆ {fname} æœ‰ {m} ç­†è£½ç¨‹ä»£è™Ÿã€‚")

            # ç¬¬1åˆ— -> m, ç¬¬2åˆ— -> m-1, ..., ç¬¬måˆ— -> 1
            for idx, code in enumerate(codes, start=1):
                value = m - idx + 1
                code_to_assembleStep[code] = value
                # print(f"    {idx}-th row, code={code}, value={value}")

    print("read_all_excel_process_code_p(), å®Œæˆï¼Œç¸½ç­†æ•¸:", len(code_to_assembleStep))
    return code_to_assembleStep


# å®‰å…¨è½‰æ•´æ•¸çš„å·¥å…·
def to_int0(v):
    if v is None:
        return 0
    s = str(v).strip()
    if s == '' or s.lower() == 'nan':
        return 0
    try:
        return int(float(s))
    except Exception:
        return 0


# ç”Ÿæˆå”¯ä¸€æª”æ¡ˆåç¨±çš„å‡½å¼
def get_unique_filename(target_dir, filename, chip):
    base, ext = os.path.splitext(filename)  # åˆ†é›¢æª”æ¡ˆåç¨±èˆ‡å‰¯æª”å
    counter = 1
    unique_filename = filename
    while os.path.exists(os.path.join(target_dir, unique_filename)):  # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨
        unique_filename = f"{base}_{chip}_{counter}{ext}"  # ç‚ºæª”åæ–°å¢å¾Œç¶´
        counter += 1
    return unique_filename


#to convert date format
def convert_date(date_value):
    try:
        return pd.to_datetime(date_value).date()  # ä½¿ç”¨ pandas è½‰æ›ç‚ºæ—¥æœŸ
    except (ValueError, TypeError):
        return None


def close_open_file(filepath):
    # éæ­·æ‰€æœ‰é€²ç¨‹
    for proc in psutil.process_iter(['pid', 'name']):
        try:
            # æª¢æŸ¥è©²é€²ç¨‹æ‰“é–‹çš„æ‰€æœ‰æ–‡ä»¶
            for item in proc.open_files():
                if item.path == filepath:
                    # å¦‚æœæ–‡ä»¶è¢«æ‰“é–‹ï¼Œå˜—è©¦é—œé–‰
                    print(f"é—œé–‰é€²ç¨‹ {proc.pid} æ‰“é–‹çš„æ–‡ä»¶: {filepath}")
                    proc.terminate()  # çµ‚æ­¢é€²ç¨‹
                    proc.wait()  # ç­‰å¾…é€²ç¨‹çµ‚æ­¢
                    return True
        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
            continue
    return False


def pad_zeros(str):
  return str.zfill(4)

'''
def clean_nan_values(obj):
    """
    å°‡ dict æˆ– ORM object ä¸­çš„ nan / NaT è½‰æ›ç‚º None
    """
    if isinstance(obj, dict):
        for k, v in obj.items():
            if isinstance(v, float) and math.isnan(v):
                obj[k] = None
            elif isinstance(v, pd._libs.tslibs.nattype.NaTType):
                obj[k] = None
    else:
        # è™•ç† SQLAlchemy ORM ç‰©ä»¶
        for attr, value in vars(obj).items():
            if attr.startswith("_"):  # è·³é SQLAlchemy ç§æœ‰å±¬æ€§
                continue
            if isinstance(value, float) and math.isnan(value):
                setattr(obj, attr, None)
            elif isinstance(value, pd._libs.tslibs.nattype.NaTType):
                setattr(obj, attr, None)
    return obj


def normalize_order_number(value):
    """å°‡å–®è™Ÿè½‰ç‚ºç´”å­—ä¸²ï¼Œä¸å¸¶å°æ•¸é»"""
    if pd.isna(value):
        return ''
    try:
        return str(int(float(value)))  # ä¾‹å¦‚ 121100017702.0 -> '121100017702'
    except ValueError:
        return str(value).strip()
'''

def clean_nan(value):
    """æ¸…ç†å–®ä¸€å€¼çš„ NaN / NaTï¼Œè½‰ç‚º None"""
    if pd.isna(value) or str(value).lower() == 'nan':
        return None
    return value

def normalize_order_number(value):
    """
    å°‡å–®è™Ÿè½‰ç‚ºç´”å­—ä¸²ï¼Œä¸å¸¶å°æ•¸é»ï¼Œä¸¦è™•ç† NaNã€‚
    ä¾‹å¦‚ï¼š121100017702.0 -> '121100017702'
    """
    if pd.isna(value) or str(value).lower() == 'nan':
        return ''
    try:
        return str(int(float(value)))
    except (ValueError, TypeError):
        return str(value).strip()


@excelTable.route("/fetchGlobalVar", methods=['GET'])
def fetch_global_var():
  print("fetchGlobalVar....")

  global global_var
  return jsonify({'value': global_var})


@excelTable.route("/countExcelFilesP", methods=['GET'])
def count_excel_files_p():
    print("countExcelFilesP....")

    _base_dir = current_app.config['baseDir']
    _target_dir = _base_dir.replace("_in", "_out")
    _base_dir = _base_dir.replace("_in", "_in_p")
    print("read excel files, ç›®éŒ„: ", _base_dir)
    print("move excel files to, ç›®éŒ„: ", _target_dir)

    path_pattern = f"{_base_dir}/*.xlsx"

    files = glob.glob(path_pattern)         # æ‰¾åˆ°æ‰€æœ‰ç¬¦åˆæ¢ä»¶çš„æª”æ¡ˆ
    count = len(files)                      # è¨ˆç®—æª”æ¡ˆæ•¸é‡
    print("count:", count)

    return jsonify({
      'count': count
    })


@excelTable.route("/countExcelFiles", methods=['GET'])
def count_excel_files():
    print("countExcelFiles....")

    _base_dir = current_app.config['baseDir']

    # æ§‹å»ºè·¯å¾‘æ¨¡å¼ï¼ŒåŒ¹é…ä»¥ "Report_" é–‹é ­çš„ .xlsx æª”æ¡ˆ
    #path_pattern = f"{_base_dir}/Report_*.xlsx"
    path_pattern = f"{_base_dir}/*.xlsx"
    # ä½¿ç”¨ glob æ‰¾åˆ°æ‰€æœ‰ç¬¦åˆæ¢ä»¶çš„æª”æ¡ˆ
    files = glob.glob(path_pattern)
    # è¨ˆç®—æª”æ¡ˆæ•¸é‡
    count = len(files)
    print("count:", count)
    # å¦‚æœæ²’æœ‰æ‰¾åˆ°æª”æ¡ˆï¼Œè¿”å›0
    #return count if count > 0 else 0
    return jsonify({
      'count': count
    })


@excelTable.route("/readAllExcelFilesP", methods=['GET'])
def read_all_excel_files_p():
  print("readAllExcelFilesP....")

  global global_var_p

  return_value = False
  return_message1 = 'éŒ¯èª¤, æ²’æœ‰å·¥å–®æª”æ¡ˆ!'
  file_count_total = 0  #æª”æ¡ˆç¸½æ•¸

  code_to_assembleStep = read_all_excel_process_code_p()
  #print("code_to_assembleStep:", code_to_assembleStep)

  _base_dir = current_app.config['baseDir']
  _target_dir = _base_dir.replace("_in", "_out")
  _base_dir = _base_dir.replace("_in", "_in_p")
  print("read excel files, ç›®éŒ„: ", _base_dir)
  print("move excel files to, ç›®éŒ„: ", _target_dir)

  # è®€å–æŒ‡å®šç›®éŒ„ä¸‹çš„æ‰€æœ‰æŒ‡å®šæª”æ¡ˆåç¨±
  files = [
     f for f in os.listdir(_base_dir)
     if os.path.isfile(os.path.join(_base_dir, f))
     and f.endswith('.xlsx')
  ]

  if not files:
    return jsonify({'status': False, 'message': return_message1})

  sheet_names_to_check = [
    current_app.config['excel_product_sheet'],
    current_app.config['excel_bom_sheet'],
    current_app.config['excel_work_time_sheet']
  ]

  s = Session()

  for _file_name in files:  #æª”æ¡ˆè®€å–, for loop_1
    file_count_total +=1
    file_name_base = re.sub(r'_copy_\d+', '', _file_name)   # å¾æª”åä¸­ç§»é™¤åƒ _copy_1ã€_copy_2 é€™æ¨£çš„å­—ä¸²ï¼Œå–å¾—åŸå§‹æª”æ¡ˆåç¨±

    # æª¢æŸ¥æ˜¯å¦å·²è™•ç†é
    already_processed = s.query(
      exists().where(ProcessedFile.file_name == file_name_base)
    ).scalar()

    if already_processed:
      temp_msg =f"æª”æ¡ˆ {_file_name} å·²è™•ç†éï¼Œ è«‹å†é‡æ•´ç€è¦½å™¨!"
      print(temp_msg)
      _path = os.path.join(_base_dir, _file_name)
      file_count_total -=1
      return_message1 = temp_msg
    else:
      _path = _base_dir + '\\' + _file_name
      global_var = _path + ' æª”æ¡ˆè®€å–ä¸­...'

      with open(_path, 'rb') as file:   # with loop_1_a
        workbook = openpyxl.load_workbook(filename=file, read_only=True)
        return_value = True
        return_message1 = ''

        print("workbook.sheetnames:", workbook.sheetnames)

        missing_sheets = [
          sheet for sheet in sheet_names_to_check if sheet not in workbook.sheetnames
        ]

        if missing_sheets:
          return jsonify({'status': False, 'message': 'éŒ¯èª¤, å·¥å–®æª”æ¡ˆå…§æ²’æœ‰ç›¸é—œå·¥ä½œè¡¨!'})

        print(sheet_names_to_check[0] + ' sheet exists, data reading...')

        material_df = pd.read_excel(_path, sheet_name=0)  # First sheet for Material
        bom_df = pd.read_excel(_path, sheet_name=1).fillna('')
        assemble_df = pd.read_excel(_path, sheet_name=2).fillna('')
        print("assemble_df columns:", list(assemble_df.columns))

        # è™•ç† BOM å’Œ Assemble çš„ è¨‚å–®æ¬„ä½
        if 'è¨‚å–®' in bom_df.columns:
          bom_df.iloc[:, 0] = (
              bom_df.iloc[:, 0]
              .apply(normalize_order_number)
              .replace('nan', '')
              .astype(str)
          )
          bom_df = bom_df.astype({bom_df.columns[0]: object})   # æŠŠ dtype è¨­æˆ object
        else:
          # å¦‚æœæ²’è³‡æ–™ï¼Œå»ºç«‹ä¸€å€‹ç©ºçš„ DataFrameï¼Œæˆ–ç›´æ¥è·³é
          bom_df = pd.DataFrame(columns=["è¨‚å–®"])  # é è¨­ç©ºçµæ§‹
          print("âš ï¸ bom_df æ²’æœ‰è³‡æ–™æˆ–ç¼ºå°‘ 'è¨‚å–®' æ¬„ä½ï¼Œå·²å»ºç«‹ç©º DataFrame")
        # end if

        print("bom_df:", bom_df, len(bom_df) )

        if 'è¨‚å–®' in assemble_df.columns:
            assemble_df['è¨‚å–®'] = (
                assemble_df['è¨‚å–®']
                .apply(normalize_order_number)
                .replace('nan', '')
                .astype(str)
            )
            assemble_df = assemble_df.astype({'è¨‚å–®': object})
        else:
            # å¦‚æœæ²’æœ‰è¨‚å–®æ¬„ä½ï¼Œå°±å°å‡ºè­¦å‘Šï¼Œå¾Œé¢å°±ä¸€å®šæŠ“ä¸åˆ°è³‡æ–™
            print("âš ï¸ assemble_df ç¼ºå°‘ 'è¨‚å–®' æ¬„ä½ï¼Œç„¡æ³•ä¾è¨‚å–®éæ¿¾å·¥åºè³‡æ–™! columns =", list(assemble_df.columns))

        # å…ˆè¨˜éŒ„æ•´å€‹ BOM sheet æ˜¯å¦å®Œå…¨æ²’è³‡æ–™
        bom_df_is_empty = bom_df.empty

        # è™•ç† Material
        for _, row in material_df.iterrows(): # for loop_material
          order_num = normalize_order_number(row.get('å–®è™Ÿ'))
          if not order_num:
            print(f"[è­¦å‘Š] å–®è™Ÿç‚ºç©ºï¼Œè·³éè©²ç­†è³‡æ–™: {row.to_dict()}")
            continue

          # å…ˆæª¢æŸ¥ BOM æ˜¯å¦æœ‰è³‡æ–™
          if bom_df_is_empty:
              # æ•´å€‹ BOM sheet æ˜¯ç©ºçš„æƒ…æ³ï¼š
              # ğŸ‘‰ ä¸è¦ç•¥éï¼Œå¾Œé¢æœƒå¹«é€™å€‹å–®è™Ÿå»ºç«‹ä¸€ç­†ã€Œé è¨­ã€çš„ P_Bom
              bom_entries = None
              print(f"[é è¨­] æ•´é«” BOM ç‚ºç©ºï¼Œå–®è™Ÿ {order_num} ä»å»ºç«‹ Material / Product / Assembleï¼Œä¸¦å»º 1 ç­†é è¨­ P_Bomã€‚")
          else:
            bom_entries = bom_df[bom_df['è¨‚å–®'] == order_num]
            if bom_entries.empty:
                print(f"[ç•¥é] å–®è™Ÿ {order_num} æ²’æœ‰ BOM è³‡æ–™ï¼Œä¸å»ºç«‹ Material")
                continue   # ç›´æ¥è·³éï¼Œä¸å»º Material / Product / Assemble

          # data
          # --------- æœ‰ BOM æ‰å»ºç«‹ Material ----------
          tempQty = clean_nan(row.get('æ•¸é‡')) or 0
          temp_sd_time_B100 = clean_nan(row.get('B100åŠ å·¥(ä¸€)å·¥æ™‚(åˆ†)')) or 0
          temp_sd_time_B102 = clean_nan(row.get('B102KLåŠ å·¥ç¶œåˆå·¥æ™‚(åˆ†)')) or 0
          temp_sd_time_B103 = clean_nan(row.get('B103KTåŠ å·¥å·¥æ™‚(åˆ†)')) or 0
          temp_sd_time_B107 = clean_nan(row.get('B107éœ‡å‹•ç ”ç£¨å·¥æ™‚(åˆ†)')) or 0
          temp_sd_time_B108 = clean_nan(row.get('B108ç¶œåˆåŠ å·¥å·¥æ™‚(åˆ†)')) or 0

          material_isBom = bom_df_is_empty
          material_isTakeOk = bom_df_is_empty

          material = P_Material(
            order_num=order_num,
            material_num=clean_nan(row.get('æ–™è™Ÿ')) or '',
            material_comment=clean_nan(row.get('èªªæ˜')) or '',
            material_qty=tempQty,
            material_date=convert_date(row.get('ç«‹å–®æ—¥')),
            material_delivery_date=convert_date(row.get('äº¤æœŸ')),
            total_delivery_qty=tempQty,
            sd_time_B100="{:.2f}".format(float(temp_sd_time_B100)),
            sd_time_B102="{:.2f}".format(float(temp_sd_time_B102)),
            sd_time_B103="{:.2f}".format(float(temp_sd_time_B103)),
            sd_time_B107="{:.2f}".format(float(temp_sd_time_B107)),
            sd_time_B108="{:.2f}".format(float(temp_sd_time_B108)),
            move_by_automatic_or_manual = False,
            move_by_process_type = 4,
            isBom = material_isBom,
            isTakeOk = material_isTakeOk,
          )
          s.add(material)
          s.flush()  # ç¢ºä¿ material.id å¯ç”¨

          # Product
          product = P_Product(material_id=material.id)
          s.add(product)
          s.commit()

          # BOM
          if not bom_df_is_empty: # bom_df_is_empty if block
              # ä¸€èˆ¬æƒ…æ³ï¼šæœ‰ BOM è³‡æ–™ï¼Œå°±æŒ‰åŸæœ¬é‚è¼¯ä¾æ“šè¨‚å–®ç·¨è™Ÿå»ºç«‹å¤šç­† P_Bom
              bom_entries = bom_df[bom_df['è¨‚å–®'] == order_num]
              print(f"bom_entries ä¸­çš„è³‡æ–™ç­†æ•¸: {len(bom_entries)}")

              for _, bom_row in bom_entries.iterrows():  # for loop_bom
                  shortage = to_int0(bom_row.get('ç‰©æ–™çŸ­ç¼º'))
                  bom = P_Bom(
                      material_id=material.id,
                      seq_num=clean_nan(bom_row.get('é ç•™é …ç›®')),
                      material_num=clean_nan(bom_row.get('ç‰©æ–™')),
                      material_comment=clean_nan(bom_row.get('ç‰©æ–™èªªæ˜')),
                      req_qty=clean_nan(bom_row.get('éœ€æ±‚æ•¸é‡')),
                      start_date=convert_date(row.get('äº¤æœŸ')),
                      lack_bom_qty=shortage,
                      receive=(shortage == 0),
                  )
                  s.add(bom)
              # end for loop_bom
          else:
              # âš ï¸ ç‰¹ä¾‹ï¼šæ•´å€‹ BOM sheet æ˜¯ç©ºçš„ (bom_df: Empty DataFrame)
              # ç‚ºæ¯ä¸€å€‹ Material å»ºç«‹ä¸€ç­†ã€Œé è¨­ã€çš„ P_Bom
              print(f"[é è¨­ BOM] å–®è™Ÿ {order_num} BOM ç‚ºç©ºï¼Œå»ºç«‹ 1 ç­†é è¨­ P_Bom")
              bom = P_Bom(
                  material_id=material.id,
                  seq_num='',
                  material_num='',
                  material_comment='é è¨­BOM (åŸå§‹Excelç„¡BOMè³‡æ–™)',
                  req_qty=0,   # é€™è£¡å¦‚æœä½ å¸Œæœ›ç­‰æ–¼ tempQty ä¹Ÿå¯ä»¥æ”¹æˆ tempQty
                  start_date=convert_date(row.get('äº¤æœŸ')),
                  lack_bom_qty=0,
                  receive=True,
              )
              s.add(bom)
          # end bom_df_is_empty if block
          s.commit()

          # Assemble
          if 'è¨‚å–®' not in assemble_df.columns:
              print(f"âš ï¸ assemble_df æ²’æœ‰ 'è¨‚å–®' æ¬„ä½ï¼Œç„¡æ³•ç”¢ç”Ÿè©²å·¥å–®çš„ P_Assembleï¼Œorder_num={order_num}")
              assemble_entries = assemble_df.iloc[0:0]  # ç©ºçš„ DataFrame
          else:
              assemble_entries = assemble_df[assemble_df['è¨‚å–®'] == order_num]

          print(f"assemble_entries ä¸­çš„è³‡æ–™ç­†æ•¸: {len(assemble_entries)}")
          # é™„å¸¶å°å‡ºå‰å¹¾ç­†è¨‚å–®æ¬„ä½ï¼Œå¹«åŠ© debug
          # print('assemble_df è¨‚å–®æ¬„ä½å‰å¹¾ç­†:', assemble_df['è¨‚å–®'].head().tolist())

          processed_work_nums = set()
          """
          for _, assemble_row in assemble_entries.iterrows(): # for loop_assemble
            workNum = clean_nan(assemble_row.get('å·¥ä½œä¸­å¿ƒ'))
            if not workNum or workNum in processed_work_nums:
              continue
            processed_work_nums.add(workNum)

            code = workNum[1:]
            step_code = code_to_assembleStep.get(code, 0)
            abnormal_field = False

            assemble = P_Assemble(
                material_id=material.id,
                material_num=clean_nan(assemble_row.get('ç‰©æ–™')),
                material_comment=clean_nan(assemble_row.get('ç‰©æ–™èªªæ˜')),
                seq_num=clean_nan(assemble_row.get('ä½œæ¥­')),
                work_num=workNum,
                process_step_code=step_code,
                input_abnormal_disable=abnormal_field,
                user_id=''
            )
            s.add(assemble)
          """
          for idx, (row_idx, assemble_row) in enumerate(assemble_entries.iterrows(), start=1):  # for loop_assemble
            print(f"  [Assemble] ç¬¬ {idx} ç­† assemble_row åŸå§‹è³‡æ–™:", assemble_row.to_dict())

            workNum = clean_nan(assemble_row.get('æ¨™æº–å…§æ–‡ç¢¼'))
            print("    â–¶ workNum(raw after clean_nan):", repr(workNum))

            # å…ˆç¢ºèªæ˜¯ä¸æ˜¯å› ç‚º workNum ç‚ºç©ºè¢«è·³é
            if not workNum:
              print("    âš ï¸ workNum ç‚ºç©ºï¼Œç•¥éé€™ç­†å·¥åºã€‚")
              continue

            if workNum in processed_work_nums:
              print(f"    âš ï¸ workNum {workNum} é‡è¤‡ï¼Œå·²è™•ç†éï¼Œç•¥éã€‚")
              continue
            processed_work_nums.add(workNum)

            # å– code & step_code
            if len(workNum) > 1:
              code = workNum[1:]
            else:
              code = workNum  # å®‰å…¨ä¸€é»ï¼Œé¿å… workNum åªæœ‰ 1 å€‹å­—çš„æ™‚å€™ [1:] è®Šæˆç©ºå­—ä¸²

            step_code = code_to_assembleStep.get(code, 0)
            print(f"    â–¶ code: {repr(code)}, step_code: {step_code}")

            abnormal_field = False

            assemble = P_Assemble(
                material_id=material.id,
                material_num=clean_nan(assemble_row.get('ç‰©æ–™')),
                material_comment=clean_nan(assemble_row.get('ç‰©æ–™èªªæ˜')),
                seq_num=clean_nan(assemble_row.get('ä½œæ¥­')),
                work_num=workNum,
                process_step_code=step_code,
                input_abnormal_disable=abnormal_field,
                user_id=''
            )
            print("    âœ… æº–å‚™æ–°å¢ P_Assemble:", assemble)
            s.add(assemble)

          # end loop_assemble
          s.commit()

          # commit å¾Œå†æŸ¥ä¸€æ¬¡çœ‹é€™å€‹ material_id åˆ°åº•æœ‰å¹¾ç­†
          cnt = s.query(P_Assemble).filter_by(material_id=material.id).count()
          print(f"  [Assemble] material_id={material.id} åœ¨ P_Assemble ç›®å‰ç¸½å…±æœ‰ {cnt} ç­†")
          # end loop_assemble
          s.commit()
        # end els loop
      # end for loop_material

        # âœ… è³‡æ–™è™•ç†å®Œå¾Œï¼Œè¨˜éŒ„æª”æ¡ˆè™•ç†ç´€éŒ„
        processed_file = ProcessedFile(file_name=file_name_base)
        s.add(processed_file)
        s.commit()

    # ç§»å‹•è™•ç†å®Œæˆçš„æª”æ¡ˆ
    try:
      unique_filename = get_unique_filename(_target_dir, _file_name, "copy")
      unique_target_path = os.path.join(_target_dir, unique_filename)
      print("unique_target_path:", unique_target_path)
      shutil.move(_path, unique_target_path)
      print(f"æª”æ¡ˆ {_path} å·²æˆåŠŸç§»å‹•åˆ° {unique_target_path}")
    except Exception as e:
      print(f"ç§»å‹•æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    continue

  #end for loop_1
  s.close()

  return jsonify({
    'status': return_value,
    'message': return_message1,
  })


@excelTable.route("/readAllExcelFiles", methods=['GET'])
def read_all_excel_files():
  print("readAllExcelFiles....")

  global global_var

  return_value = False
  return_message1 = 'éŒ¯èª¤, æ²’æœ‰å·¥å–®æª”æ¡ˆ!'
  file_count_total = 0  #æª”æ¡ˆç¸½æ•¸

  # 2025-06-12, æ”¹é †åº
  code_to_assembleStep = {    #çµ„è£å€å·¥ä½œé †åº, 3:æœ€å„ªå…ˆ
    '109': 3,
    #'106': 2, '110': 1,
    '106': 1, '110': 2,
  }

  _base_dir = current_app.config['baseDir']
  _target_dir = _base_dir.replace("_in", "_out")
  print("read excel files, ç›®éŒ„: ", _base_dir)
  print("move excel files to, ç›®éŒ„: ", _target_dir)

  ## å–å¾— excel_out å…§å·²è™•ç†æª”æ¡ˆï¼ˆç§»é™¤ _copy_x å°¾ç¢¼ä»¥ä¾¿æ¯”å°ï¼‰
  #processed_files = {
  #    re.sub(r'_copy_\d+', '', f)
  #    for f in os.listdir(_target_dir)
  #    if os.path.isfile(os.path.join(_target_dir, f)) and f.endswith('.xlsx')
  #}
  #

  # è®€å–æŒ‡å®šç›®éŒ„ä¸‹çš„æ‰€æœ‰æŒ‡å®šæª”æ¡ˆåç¨±
  #files = [f for f in os.listdir(_base_dir) if os.path.isfile(os.path.join(_base_dir, f)) and f.startswith('Report_') and f.endswith('.xlsx')]
  #files = [f for f in os.listdir(_base_dir) if os.path.isfile(os.path.join(_base_dir, f)) and f.endswith('.xlsx')]
  files = [
     f for f in os.listdir(_base_dir)
     if os.path.isfile(os.path.join(_base_dir, f))
     and f.endswith('.xlsx')
  ]

  '''
  # æ’é™¤å·²è™•ç†çš„æª”æ¡ˆ
  files = [
      f for f in os.listdir(_base_dir)
      if os.path.isfile(os.path.join(_base_dir, f))
        and f.endswith('.xlsx')
        and f not in processed_files
  ]
  '''
  if not files:
    return jsonify({'status': False, 'message': return_message1})

  #if (files):   #æœ‰å·¥å–®æª”æ¡ˆ, if condition_a
  sheet_names_to_check = [
    current_app.config['excel_product_sheet'],
    current_app.config['excel_bom_sheet'],
    current_app.config['excel_work_time_sheet']
  ]
  #_startRow = int(current_app.config['startRow'])

  s = Session()

  for _file_name in files:  #æª”æ¡ˆè®€å–, for loop_1
    file_count_total +=1
    file_name_base = re.sub(r'_copy_\d+', '', _file_name)   # å¾æª”åä¸­ç§»é™¤åƒ _copy_1ã€_copy_2 é€™æ¨£çš„å­—ä¸²ï¼Œå–å¾—åŸå§‹æª”æ¡ˆåç¨±

    # æª¢æŸ¥æ˜¯å¦å·²è™•ç†é
    already_processed = s.query(
      exists().where(ProcessedFile.file_name == file_name_base)
    ).scalar()

    if already_processed:
      temp_msg =f"æª”æ¡ˆ {_file_name} å·²è™•ç†éï¼Œ è«‹å†é‡æ•´ç€è¦½å™¨!"
      print(temp_msg)
      _path = os.path.join(_base_dir, _file_name)
      file_count_total -=1
      return_message1 = temp_msg

    #  continue
    else:
      _path = _base_dir + '\\' + _file_name
      global_var = _path + ' æª”æ¡ˆè®€å–ä¸­...'

      with open(_path, 'rb') as file:   # with loop_1_a
        workbook = openpyxl.load_workbook(filename=file, read_only=True)
        return_value = True
        return_message1 = ''

        #missing_sheets = [sheet for sheet in sheet_names_to_check if sheet not in workbook.sheetnames]
        missing_sheets = [
          sheet for sheet in sheet_names_to_check if sheet not in workbook.sheetnames
        ]

        if missing_sheets:
          return jsonify({'status': False, 'message': 'éŒ¯èª¤, å·¥å–®æª”æ¡ˆå…§æ²’æœ‰ç›¸é—œå·¥ä½œè¡¨!'})

          #return_value = False
          #return_message1 = 'éŒ¯èª¤, å·¥å–®æª”æ¡ˆå…§æ²’æœ‰ç›¸é—œå·¥ä½œè¡¨!'
          #print(return_message1)
          #break

        print(sheet_names_to_check[0] + ' sheet exists, data reading...')

        material_df = pd.read_excel(_path, sheet_name=0)  # First sheet for Material
        # 2025-09-09 add
        # æ¬„ä½ç´šæ­£è¦åŒ–
        if 'å–®è™Ÿ' in material_df.columns:
          material_df['å–®è™Ÿ'] = (
              material_df['å–®è™Ÿ']
              .apply(normalize_order_number)
              .astype(str)
              .replace('nan', '')
          )
        #
        #bom_df = pd.read_excel(_path, sheet_name=1).fillna('')
        #
        bom_df = pd.read_excel(_path, sheet_name=1)
        # æ–‡æœ¬æ¬„ä½å¯è£œç©ºå­—ä¸²
        for col in ['ç‰©æ–™', 'ç‰©æ–™èªªæ˜']:
          if col in bom_df.columns:
            bom_df[col] = bom_df[col].fillna('')
        # æ•¸å€¼æ¬„ä½è½‰æ•¸å­—
        for col in ['ç‰©æ–™çŸ­ç¼º', 'éœ€æ±‚æ•¸é‡', 'é ç•™é …ç›®']:
          if col in bom_df.columns:
            bom_df[col] = pd.to_numeric(bom_df[col], errors='coerce').fillna(0).astype(int)
        #
        assemble_df = pd.read_excel(_path, sheet_name=2).fillna('')

        # çµ±ä¸€è™•ç† BOM å’Œ Assemble çš„ è¨‚å–®æ¬„ä½
        if 'è¨‚å–®' in bom_df.columns:
          # 2025-08-11 modify
          #bom_df['è¨‚å–®'] = bom_df['è¨‚å–®'].apply(normalize_order_number)
          '''
          bom_df['è¨‚å–®'] = (
            bom_df['è¨‚å–®']
            .apply(normalize_order_number)
            .astype(str)
            .replace('nan', '')
          )
          '''
          bom_df.iloc[:, 0] = (
              bom_df.iloc[:, 0]
              .apply(normalize_order_number)
              .replace('nan', '')
              .astype(str)   # ç›´æ¥æœ€å¾Œè½‰æˆ str â†’ object
          )

          # æ˜ç¢ºæŠŠ dtype è¨­æˆ object
          bom_df = bom_df.astype({bom_df.columns[0]: object})

        # 2025-08-11 modify
        #assemble_df.iloc[:, 0] = assemble_df.iloc[:, 0].apply(normalize_order_number)
        '''
        assemble_df.iloc[:, 0] = (
          assemble_df.iloc[:, 0]
          .apply(normalize_order_number)
          .astype(str)
          .replace('nan', '')
        )
        '''
        assemble_df.iloc[:, 0] = (
            assemble_df.iloc[:, 0]
            .apply(normalize_order_number)
            .replace('nan', '')
            .astype(str)
        )
        assemble_df = assemble_df.astype({assemble_df.columns[0]: object})

        # è™•ç† Material
        for _, row in material_df.iterrows(): # for loop_material
            order_num = normalize_order_number(row.get('å–®è™Ÿ'))
            if not order_num:
                print(f"[è­¦å‘Š] å–®è™Ÿç‚ºç©ºï¼Œè·³éè©²ç­†è³‡æ–™: {row.to_dict()}")
                continue

            tempQty = clean_nan(row.get('æ•¸é‡')) or 0
            temp_sd_time_B109 = clean_nan(row.get('B109çµ„è£å·¥æ™‚(åˆ†)')) or 0
            temp_sd_time_B106 = clean_nan(row.get('B106é›·åˆ»å·¥æ™‚(åˆ†)')) or 0
            temp_sd_time_B110 = clean_nan(row.get('B110æª¢é©—å·¥æ™‚(åˆ†)')) or 0

            material = Material(
                order_num=order_num,
                material_num=clean_nan(row.get('æ–™è™Ÿ')) or '',
                material_comment=clean_nan(row.get('èªªæ˜')) or '',
                material_qty=tempQty,
                material_date=convert_date(row.get('ç«‹å–®æ—¥')),
                material_delivery_date=convert_date(row.get('äº¤æœŸ')),
                total_delivery_qty=tempQty,
                sd_time_B109="{:.2f}".format(float(temp_sd_time_B109)),
                sd_time_B106="{:.2f}".format(float(temp_sd_time_B106)),
                sd_time_B110="{:.2f}".format(float(temp_sd_time_B110)),
            )
            s.add(material)
            s.flush()  # ç¢ºä¿ material.id å¯ç”¨

            # Product
            product = Product(material_id=material.id)
            s.add(product)
            s.commit()

            # BOM
            bom_entries = bom_df[bom_df['è¨‚å–®'] == order_num]
            print(f"bom_entries ä¸­çš„è³‡æ–™ç­†æ•¸: {len(bom_entries)}")

            for _, bom_row in bom_entries.iterrows(): # for loop_bom
                #temp=clean_nan(bom_row.get('ç‰©æ–™çŸ­ç¼º'))
                shortage = to_int0(bom_row.get('ç‰©æ–™çŸ­ç¼º'))
                bom = Bom(
                    material_id=material.id,
                    seq_num=clean_nan(bom_row.get('é ç•™é …ç›®')),
                    material_num=clean_nan(bom_row.get('ç‰©æ–™')),
                    material_comment=clean_nan(bom_row.get('ç‰©æ–™èªªæ˜')),
                    req_qty=clean_nan(bom_row.get('éœ€æ±‚æ•¸é‡')),
                    start_date=convert_date(row.get('äº¤æœŸ')),
                    #lack_bom_qty=temp,
                    lack_bom_qty = shortage,
                    #receive= True if temp==0 else False,
                    receive=(shortage == 0),
                )
                s.add(bom)
            s.commit()

            # Assemble
            assemble_entries = assemble_df[assemble_df.iloc[:, 0] == order_num]
            print(f"assemble_entries ä¸­çš„è³‡æ–™ç­†æ•¸: {len(assemble_entries)}")

            processed_work_nums = set()
            for _, assemble_row in assemble_entries.iterrows(): # for loop_assemble
                workNum = clean_nan(assemble_row.get('å·¥ä½œä¸­å¿ƒ'))
                if not workNum or workNum in processed_work_nums:
                    continue
                processed_work_nums.add(workNum)

                code = workNum[1:]
                step_code = code_to_assembleStep.get(code, 0)
                #abnormal_field = (workNum == 'B109')     # 2025-07-29 modify
                abnormal_field = False

                assemble = Assemble(
                    material_id=material.id,
                    material_num=clean_nan(assemble_row.get('ç‰©æ–™')),
                    material_comment=clean_nan(assemble_row.get('ç‰©æ–™èªªæ˜')),
                    seq_num=clean_nan(assemble_row.get('ä½œæ¥­')),
                    work_num=workNum,
                    process_step_code=step_code,
                    input_abnormal_disable=abnormal_field,
                    user_id=''
                )
                s.add(assemble)
            s.commit()
        # end for loop_material

        # âœ… è³‡æ–™è™•ç†å®Œå¾Œï¼Œè¨˜éŒ„æª”æ¡ˆè™•ç†ç´€éŒ„
        processed_file = ProcessedFile(file_name=file_name_base)
        s.add(processed_file)
        s.commit()

    # ç§»å‹•è™•ç†å®Œæˆçš„æª”æ¡ˆ
    try:
      unique_filename = get_unique_filename(_target_dir, _file_name, "copy")
      unique_target_path = os.path.join(_target_dir, unique_filename)
      print("unique_target_path:", unique_target_path)
      shutil.move(_path, unique_target_path)
      print(f"æª”æ¡ˆ {_path} å·²æˆåŠŸç§»å‹•åˆ° {unique_target_path}")
    except Exception as e:
      print(f"ç§»å‹•æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    continue

  #end for loop_1
  s.close()
  #end if condition_a

  return jsonify({
    'status': return_value,
    'message': return_message1,
  })


@excelTable.route("/deleteAssemblesWithNegativeGoodQty", methods=['GET'])
def delete_assembles_with_negative_good_qty():
  print("deleteAssemblesWithNegativeGoodQty...")

  s = Session()

  # æŸ¥è©¢æ‰€æœ‰ Assemble è³‡æ–™
  _objects = s.query(Assemble).all()

  # ç”¨ä¾†è¿½è¹¤å‰ä¸€ç­†è³‡æ–™
  previous_assemble = None

  # è¿­ä»£æ¯ä¸€ç­† Assemble è³‡æ–™
  for current_assemble in _objects:
    if current_assemble.good_qty < 0:
      # å¦‚æœç™¼ç¾ ask_qty å°æ–¼ 0ï¼Œå‰‡åˆªé™¤ç•¶å‰åŠå‰ä¸€ç­† Assemble ç´€éŒ„
      if previous_assemble:
        print(f"Deleting previous assemble: {previous_assemble.id}, good_qty={previous_assemble.good_qty}")
        s.delete(previous_assemble)  # åˆªé™¤å‰ä¸€ç­† Assemble ç´€éŒ„
      print(f"Deleting current assemble: {current_assemble.id}, ask_qty={current_assemble.good_qty}")
      s.delete(current_assemble)  # åˆªé™¤ç•¶å‰ Assemble ç´€éŒ„

      # è™•ç†èˆ‡ Material çš„é—œè¯ï¼ˆå¦‚æœ‰å¿…è¦ï¼‰
      # æ ¹æ“šæ¥­å‹™é‚è¼¯æ±ºå®šæ˜¯å¦åˆªé™¤ Materialï¼Œæˆ–æ›´æ–° Material çš„æŸäº›ç‹€æ…‹
      material = s.query(Material).filter(Material.id == current_assemble.material_id).first()
      if material:
        # æ›´æ–° Material çš„æ¬„ä½ï¼Œä¾‹å¦‚ isTakeOk æˆ–å…¶ä»–ç‹€æ…‹
        # material.isTakeOk = False  # æ›´æ–°æŸäº›ç‹€æ…‹
        # å¦‚æœéœ€è¦åˆªé™¤ Materialï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ï¼š
        # s.delete(material)
        print(f"Updating or deleting related material: {material.id}, material_num={material.material_num}")

    # æ›´æ–° previous_assemble ç‚ºç•¶å‰ Assemble
    previous_assemble = current_assemble

  # æäº¤åˆªé™¤
  s.commit()
  s.close()

  return jsonify({
    'status': True,
    #'message': return_message1,
  })


@excelTable.route("/exportToExcelForError", methods=['POST'])
def export_to_excel_for_error():
    print("exportToExcelForError....")

    request_data = request.get_json()

    _blocks = request_data['blocks']
    _count = request_data['count']
    _name = request_data['name']

    print("_blocks:", _blocks)

    date = datetime.datetime.now()
    today = date.strftime('%Y-%m-%d-%H%M')
    file_name = 'çµ„è£ç•°å¸¸è¨˜éŒ„æŸ¥è©¢_'+today + '.xlsx'
    current_file = 'C:\\vue\\chumpower\\excel_export\\'+ file_name

    print("filename:", current_file)
    file_check = os.path.exists(current_file)  # true:excel file exist

    return_value = True  # true: export into excelæˆåŠŸ

    if file_check:
      try:
        os.remove(current_file)  # åˆªé™¤èˆŠæª”æ¡ˆ
      except PermissionError:
        print(f"ç„¡æ³•åˆªé™¤ {current_file}ï¼Œè«‹ç¢ºèªæ˜¯å¦å·²é—œé–‰è©²æª”æ¡ˆ")
        return_value = False
        return jsonify({"success": False, "message": "è«‹é—œé–‰ Excel æª”æ¡ˆå¾Œé‡è©¦"})
    #if file_check:
    #  wb = openpyxl.load_workbook(current_file)  # é–‹å•Ÿç¾æœ‰çš„ Excel æ´»é ç°¿ç‰©ä»¶
    #else:
    #  wb = Workbook()     # å»ºç«‹ç©ºç™½çš„ Excel æ´»é ç°¿ç‰©ä»¶
    wb = Workbook()     # å»ºç«‹ç©ºç™½çš„ Excel æ´»é ç°¿ç‰©ä»¶
    # ws = wb.active
    ws = wb.worksheets[0]   # å–å¾—ç¬¬ä¸€å€‹å·¥ä½œè¡¨

    ws.title = 'çµ„è£ç•°å¸¸è¨˜éŒ„æŸ¥è©¢-' + _name                # ä¿®æ”¹å·¥ä½œè¡¨ 1 çš„åç¨±ç‚º oxxo
    ws.sheet_properties.tabColor = '7da797'  # ä¿®æ”¹å·¥ä½œè¡¨ 1 é ç±¤é¡è‰²ç‚ºç´…è‰²

    for obj in _blocks:
      temp_array = []

      # åœ¨å¯«å…¥ Excel æ™‚åšè½‰æ›
      raw_str = obj['cause_message_str']  # e.g., "æ··æ–™(M01001),æ•£çˆª(M01002),æ‰çˆª(M01003)"
      messages = [re.sub(r'\(.*?\)', '', m).strip() for m in raw_str.split(',')]  # ç§»é™¤æ‹¬è™Ÿå’Œè£¡é¢å…§å®¹
      cleaned_str = ','.join(messages)  # "æ··æ–™,æ•£çˆª,æ‰çˆª"

      temp_array.append(obj['order_num'])
      temp_array.append(obj['comment'])
      temp_array.append(obj['delivery_date'])
      temp_array.append(obj['req_qty'])
      temp_array.append(obj['delivery_qty'])
      temp_array.append(obj['user'])
      #temp_array.append(obj['cause_message_str'])
      temp_array.append(cleaned_str)
      temp_array.append(obj['cause_user'])
      temp_array.append(obj['cause_date'])

      ws.append(temp_array)

    for col in ws.columns:
      column = col[0].column_letter  # Get the column name
      temp_cell = column + '1'
      ws[temp_cell].font = Font(
          name='å¾®è»Ÿæ­£é»‘é«”', color='ff0000', bold=True)  # è¨­å®šå„²å­˜æ ¼çš„æ–‡å­—æ¨£å¼
      ws[temp_cell].alignment = Alignment(horizontal='center')
      ws.column_dimensions[column].bestFit = True

    #wb.save(current_file)
    #é é˜² Excel æª”æ¡ˆè¢«é–å®š
    temp_file = current_file.replace(".xlsx", "_temp.xlsx")
    wb.save(temp_file)
    os.replace(temp_file, current_file)  # ç”¨æ–°æª”æ¡ˆå–ä»£èˆŠæª”æ¡ˆ

    print("file_name:", file_name)

    return jsonify({
      'status': return_value,
      'message': current_file,
      'file_name': file_name,
      # 'outputs': myDir,
    })


@excelTable.route("/exportToExcelForAssembleInformation", methods=['POST'])
def export_to_excel_for_assemble_information():
    import os
    import datetime
    from flask import jsonify, request
    from openpyxl import Workbook
    from openpyxl.styles import Alignment, Font

    print("hello, exportToExcelForAssembleInformation....")

    request_data = request.get_json(force=True) or {}
    _blocks = request_data.get('blocks', [])
    _name = request_data.get('name', '')

    now = datetime.datetime.now()
    today = now.strftime('%Y-%m-%d-%H%M')
    file_name = f'çµ„è£å€åœ¨è£½å“ç”Ÿç”¢è³‡è¨ŠæŸ¥è©¢_{today}.xlsx'
    export_dir = r'C:\vue\chumpower\excel_export'
    os.makedirs(export_dir, exist_ok=True)
    current_file = os.path.join(export_dir, file_name)

    code_to_name = {
        1 : 'å‚™æ–™',
        19: 'ç­‰å¾…AGV(å‚™æ–™å€)',
        2:  'AGVé‹è¡Œ(å‚™æ–™å€->çµ„è£å€)',
        20: 'AGVé‹è¡Œåˆ°çµ„è£å€',
        21: 'çµ„è£',
        22: 'æª¢é©—',
        23: 'é›·å°„',
        29: 'ç­‰å¾…AGV(çµ„è£å€)',
        3:  'AGVé‹è¡Œ(çµ„è£å€->æˆå“å€)',
        30: 'AGVé‹è¡Œåˆ°æˆå“å€',
        31: 'æˆå“å…¥åº«',
        5:  'å †é«˜æ©Ÿé‹è¡Œ(å‚™æ–™å€->çµ„è£å€)',
        6:  'å †é«˜æ©Ÿé‹è¡Œ(çµ„è£å€->æˆå“å€)',
    }

    # === 1) å®‰å…¨æ™‚é–“è½‰æ›ï¼šåƒ str/datetime/date/Noneï¼Œå› datetime æˆ– None ===
    def to_dt(val):
        if not val:
            return None
        if isinstance(val, datetime.datetime):
            return val
        if isinstance(val, datetime.date):
            return datetime.datetime.combine(val, datetime.time.min)
        if isinstance(val, str):
            for fmt in ("%Y-%m-%d %H:%M:%S", "%Y/%m/%d %H:%M:%S",
                        "%Y-%m-%d %H:%M", "%Y/%m/%d %H:%M"):
                try:
                    return datetime.datetime.strptime(val, fmt)
                except ValueError:
                    continue
        return None

    # === 2) è‹¥èˆŠæª”å­˜åœ¨ï¼Œå˜—è©¦åˆªé™¤ï¼›å ç”¨æ™‚å›å ±è«‹é—œé–‰ ===
    if os.path.exists(current_file):
        try:
            os.remove(current_file)
        except PermissionError:
            return jsonify({"status": False, "message": "è«‹é—œé–‰ Excel æª”æ¡ˆå¾Œé‡è©¦", "file_name": ""}), 200

    # === 3) å»ºç°¿/è¡¨é ­ ===
    wb = Workbook()
    ws = wb.worksheets[0]
    ws.title = 'çµ„è£å€åœ¨è£½å“ç”Ÿç”¢è³‡è¨ŠæŸ¥è©¢-' + _name
    ws.sheet_properties.tabColor = '7da797'

    header = ['è¨‚å–®ç·¨è™Ÿ', 'èªªæ˜', 'äº¤æœŸ', 'è¨‚å–®æ•¸é‡', 'ç¾æ³æ•¸é‡', 'å·¥åº', 'é–‹å§‹æ™‚é–“', 'çµæŸæ™‚é–“']
    ws.append(header)
    for idx, _ in enumerate(header, start=1):
        cell = ws.cell(row=1, column=idx)
        cell.font = Font(name='å¾®è»Ÿæ­£é»‘é«”', color='FF0000', bold=True)
        cell.alignment = Alignment(horizontal='center')
        ws.column_dimensions[cell.column_letter].width = 16

    s = Session()
    temp_file = current_file.replace(".xlsx", "_temp.xlsx")

    try:
        for obj in _blocks:
            order_num = obj.get('order_num', '')
            # å…ˆå¯« Material ä¸»åˆ—
            ws.append([
                order_num,
                obj.get('comment', ''),
                obj.get('delivery_date', ''),
                obj.get('req_qty', ''),
                obj.get('delivery_qty', ''),
                '', '', ''  # è®“å‡ºå·¥åº/é–‹å§‹/çµæŸæ¬„ä½
            ])

            material = s.query(Material).filter(Material.order_num == order_num).first()

            # å–ç¸½é‡ï¼ˆå¯èƒ½ Noneï¼‰
            work_qty = (material.total_delivery_qty if material and getattr(material, "total_delivery_qty", None) else 0)

            processes = material._process if (material and getattr(material, "_process", None)) else []
            for process in processes:
                ptype = getattr(process, "process_type", None)
                status = code_to_name.get(ptype, 'ç©ºç™½')

                # === 4) å“¡å·¥è³‡è¨Šï¼ˆå¯èƒ½æ²’æœ‰ï¼‰===
                emp_id = (getattr(process, "user_id", "") or "")
                if emp_id:
                    user = s.query(User).filter_by(emp_id=emp_id).first()
                    emp_short = emp_id.lstrip("0") if isinstance(emp_id, str) else str(emp_id)
                    if user and getattr(user, "emp_name", None):
                        status = f"{status}({emp_short}{user.emp_name})"

                # === 5) å®‰å…¨æ™‚é–“è§£æ + é€²è¡Œä¸­è™•ç† ===
                start_dt = to_dt(getattr(process, "begin_time", None))
                end_dt = to_dt(getattr(process, "end_time", None)) if ptype != 31 else None

                # é€²è¡Œä¸­ï¼šend_dt ç‚º None â†’ ä½ å¯ä»¥é¸ï¼šA é¡¯ç¤ºç©ºç™½ï¼ˆé€™ç‰ˆç”¨ç©ºç™½ï¼‰ï¼ŒB ç”¨ now ç•¶æš«æ­¢
                effective_end = end_dt if end_dt is not None else (now if start_dt else None)

                # å€æ®µåˆ†é˜ï¼ˆä¸ä¸€å®šè¦å¯«å…¥ï¼›çµ¦ä½ æœªä¾†ç®—å–®ä»¶å·¥æ™‚ç”¨ï¼‰
                period_minutes = None
                if start_dt and effective_end:
                    td = effective_end - start_dt
                    if td.total_seconds() >= 0:
                        period_minutes = int(td.total_seconds() // 60)

                # === 6) è¼¸å‡ºåˆ° Excelï¼ˆæ™‚é–“æ¬„ä½åšå®‰å…¨æ ¼å¼åŒ–ï¼‰===
                def fmt(dt):
                    return dt.strftime("%Y-%m-%d %H:%M:%S") if isinstance(dt, datetime.datetime) else ''

                ws.append([
                    '', '', '', '', '',
                    status,
                    fmt(start_dt),
                    fmt(end_dt),   # æƒ³é¡¯ç¤ºã€Œç›®å‰æ™‚é–“ã€å°±æ”¹æˆ fmt(effective_end)
                ])

        # === 7) å…ˆå­˜æš«å­˜æª”å†åŸå­æ›¿æ› ===
        wb.save(temp_file)
        os.replace(temp_file, current_file)

        print("file_name:", file_name)
        return jsonify({'status': True, 'message': current_file, 'file_name': file_name}), 200

    except Exception as e:
        s.rollback()
        try:
            if os.path.exists(temp_file):
                os.remove(temp_file)
        except Exception:
            pass
        print("export_to_excel_for_assemble_information EXCEPTION:", repr(e))
        return jsonify({'status': False, 'message': f'åŒ¯å‡ºå¤±æ•—: {e}', 'file_name': ''}), 500
    finally:
        s.close()


# ä¸Šå‚³.xlsxå·¥å–®æª”æ¡ˆçš„ API
@excelTable.route('/uploadExcelFile', methods=['POST'])
def upload_excel_file():
  print("uploadExcelFile....")

  _base_dir = current_app.config['baseDir']

  # ä»¥ baseDir çš„ä¸Šå±¤ä½œç‚ºæ ¹ç›®éŒ„ï¼ˆé€šå¸¸ baseDir æœƒæ˜¯ .../excel_inï¼‰
  base_dir_default = os.path.abspath(current_app.config['baseDir'])
  root_dir = os.path.abspath(os.path.dirname(base_dir_default))

  if not os.path.exists(_base_dir):
    os.makedirs(_base_dir)

  file = request.files.get('file')

  _upload_type = request.form.get('uploadType')
  upload_type=_upload_type.strip()
  print("uploadType:", upload_type)

  if not file:
    return jsonify({'message': 'æ²’æœ‰é¸æ“‡æª”æ¡ˆ'}), 400

  # ç¢ºä¿æ˜¯ Excel æª”æ¡ˆ
  if not file.filename.endswith(('.xlsx', '.xls')):
    return jsonify({'message': 'åªå…è¨±ä¸Šå‚³ Excel æª”æ¡ˆ'}), 400

  if file.filename == '':
    return jsonify({'message': 'æ²’æœ‰é¸æ“‡æª”æ¡ˆ'}), 400

  if upload_type == "excelp":
    print("step1...")
    _base_dir = os.path.join(os.path.dirname(_base_dir), "excel_in_p")
    print("base_dir:", _base_dir)

  if upload_type == "excelm":
    print("step2...")
    _base_dir = os.path.join(os.path.dirname(_base_dir), "excel_modify")
    print("base_dir:", _base_dir)

  #

  #
  file_path = os.path.join(_base_dir, file.filename)
  print("file_path:",file_path)

  # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨
  if os.path.exists(file_path):
    #return jsonify({'message': f'æª”æ¡ˆ "{file.filename}" å·²å­˜åœ¨'}), 400
    unique_filename = get_unique_filename(_base_dir, file.filename, "copy")
    file_path = os.path.join(_base_dir, unique_filename)

  file.save(file_path)

  try:
    with open(file_path, 'rb') as f:
        print(f"æª”æ¡ˆæˆåŠŸå„²å­˜ä¸¦å¯è®€å–: {file_path}")
        return jsonify({
          'message': 'ä¸Šå‚³æˆåŠŸ',
          'filename': file.filename,
          'status': True,
        })
  except Exception as e:
      print(f"æª”æ¡ˆå„²å­˜å¾Œè®€å–å¤±æ•—: {str(e)}")
      return jsonify({'message': f'æª”æ¡ˆå„²å­˜å¾Œè®€å–å¤±æ•—: {str(e)}'}), 500
  #return jsonify({'message': 'ä¸Šå‚³æˆåŠŸ', 'filename': file.filename}), 200


@excelTable.route('/uploadPdfFiles', methods=['POST'])
def upload_pdf_files():
  print("uploadPdfFiles....")

  _base_dir = current_app.config['pdfBaseDir']

  upload_type = request.form.get('uploadType')
  # æ ¹æ“š uploadType å‹•æ…‹èª¿æ•´å„²å­˜ç›®éŒ„
  if upload_type == 'pdf1':
      _base_dir = _base_dir.replace('ç‰©æ–™æ¸…å–®', 'é ˜é€€æ–™å–®')
  if not os.path.exists(_base_dir):
    os.makedirs(_base_dir)
  print("å¯¦éš›å„²å­˜è·¯å¾‘:", _base_dir)

  files = request.files.getlist('files')  # multiple files

  if not files or len(files) == 0:
    return jsonify({'message': 'æ²’æœ‰é¸æ“‡æª”æ¡ˆ'}), 400

  saved_files = []
  for file in files:
    print("file.filename:",file.filename)

    if not file.filename.endswith('.pdf'):
      return jsonify({'message': f'æª”æ¡ˆ {file.filename} ä¸æ˜¯ PDF'}), 400

    filename = file.filename
    filename = os.path.basename(filename)
    file_path = os.path.join(_base_dir, filename)

    if os.path.exists(file_path):
      filename = get_unique_filename(_base_dir, filename, "copy")
      file_path = os.path.join(_base_dir, filename)

    file.save(file_path)
    saved_files.append(filename)

  return jsonify({
    'message': f'{len(saved_files)} å€‹ PDF æª”æ¡ˆä¸Šå‚³æˆåŠŸ',
    'files': saved_files,
    'status': True
  })


# å…§éƒ¨ï¼šå¥—ç”¨ BOM å·®ç•°(åŸ apply_bom_diffs çš„æ ¸å¿ƒï¼›ä¸å°å¤–æˆ route)
def _apply_bom_diffs_tx(s, material: Material, ops: list):
    """
    ç›´æ¥æŠŠå·®ç•°ï¼ˆadd/update/removeï¼‰å¥—ç”¨åˆ° DBã€‚å›å‚³(çµæœæ‘˜è¦, material çš„æœ€æ–° BOM åˆ—è¡¨)ã€‚
    """
    # å…ˆæŠ“ç¾æœ‰ BOMï¼Œå»ºç«‹ç´¢å¼•
    existing = s.query(Bom).filter(Bom.material_id == material.id).all()
    by_key, by_mnum = {}, {}
    for b in existing:
        k = (str(b.seq_num).strip(), str(b.material_num).strip())
        by_key[k] = b
        by_mnum.setdefault(str(b.material_num).strip(), []).append(b)

    def _to_int(x, default=0):
        try:
            if x is None or (isinstance(x, str) and x.strip() == ""):
                return default
            return int(float(x))
        except Exception:
            return default

    def _recompute_non_qty(b: Bom):
        req = _to_int(b.req_qty, 0)
        picked = _to_int(b.pick_qty, 0)
        b.non_qty = max(req - picked, 0)

    results = {"added": [], "updated": [], "removed": []}

    for op in ops:
        action = (op.get("action") or "").strip().lower()
        seq_num = str(op.get("seq_num") or "").strip()
        mnum = str(op.get("material_num") or "").strip()
        if not mnum:
            continue

        target = by_key.get((seq_num, mnum))
        if not target and seq_num == "" and mnum in by_mnum and len(by_mnum[mnum]) == 1:
            target = by_mnum[mnum][0]

        if action == "add":
            comment = op.get("mtl_comment", op.get("material_comment", ""))
            qty = op.get("qty", op.get("req_qty", 0))
            start_date = op.get("start_date") or material.material_delivery_date
            receive = op.get("receive", True)

            new_bom = Bom(
                material_id=material.id,
                seq_num=seq_num or op.get("id") or "0",
                material_num=mnum,
                material_comment=str(comment or ""),
                req_qty=_to_int(qty, 0),
                pick_qty=0,
                lack_qty=0,
                non_qty=0,
                receive=bool(receive),
                start_date=str(start_date or ""),
            )
            _recompute_non_qty(new_bom)
            s.add(new_bom)
            s.flush()
            by_key[(str(new_bom.seq_num), mnum)] = new_bom
            by_mnum.setdefault(mnum, []).append(new_bom)
            results["added"].append(new_bom.get_dict())

        elif action == "update":
            if not target:
                results["updated"].append({"material_num": mnum, "seq_num": seq_num, "skipped": "not_found"})
                continue
            new_comment = op.get("mtl_comment_new", op.get("material_comment"))
            new_qty = op.get("qty_new", op.get("req_qty"))
            new_seq = op.get("seq_num_new")
            changed = False
            if new_comment is not None and str(target.material_comment) != str(new_comment):
                target.material_comment = str(new_comment); changed = True
            if new_qty is not None:
                v = _to_int(new_qty, target.req_qty or 0)
                if v != (target.req_qty or 0):
                    target.req_qty = v
                    _recompute_non_qty(target)
                    changed = True
            if new_seq is not None:
                ns = str(new_seq).strip()
                if ns and ns != str(target.seq_num):
                    old_key = (str(target.seq_num), mnum)
                    target.seq_num = ns
                    by_key.pop(old_key, None)
                    by_key[(ns, mnum)] = target
                    changed = True
            if changed:
                results["updated"].append(target.get_dict())
            else:
                results["updated"].append({"material_num": mnum, "seq_num": seq_num, "noop": True})

        elif action == "remove":
            if not target:
                candidates = by_mnum.get(mnum, [])
                if not candidates:
                    results["removed"].append({"material_num": mnum, "seq_num": seq_num, "skipped": "not_found"})
                    continue
                for b in list(candidates):
                    s.delete(b)
                    results["removed"].append({"id": b.id, "material_num": b.material_num, "seq_num": b.seq_num})
                    by_key.pop((str(b.seq_num), mnum), None)
                by_mnum.pop(mnum, None)
            else:
                s.delete(target)
                results["removed"].append({"id": target.id, "material_num": target.material_num, "seq_num": target.seq_num})
                by_key.pop((str(target.seq_num), mnum), None)
                if mnum in by_mnum:
                    by_mnum[mnum] = [b for b in by_mnum[mnum] if b.id != target.id]
                    if not by_mnum[mnum]:
                        by_mnum.pop(mnum, None)

    # å–å›æœ€æ–° BOM
    latest = s.query(Bom).filter(Bom.material_id == material.id).all()
    return results, [b.get_dict() for b in latest]

# å°è£ï¼šå¾ excel_modify è®€æª” â†’ ç”¢ç”Ÿå·®ç•°æ¸…å–®(æ²¿ç”¨ read_all_excel_files çš„æ¸…æ´—è¦å‰‡)
def _collect_bom_diffs_from_modify_dir(s, material: Material):
    base_in = os.path.abspath(current_app.config['baseDir'])            # e.g. ...\excel_in
    modify_dir = base_in.replace("_in", "_modify")                      # ...\excel_modify
    out_dir = base_in.replace("_in", "_out")                            # ...\excel_out
    sheet_bom = current_app.config.get('excel_bom_sheet') or 1          # ç³»çµ±æŒ‡å®šç´¢å¼• 1 = BOM

    os.makedirs(modify_dir, exist_ok=True)
    os.makedirs(out_dir, exist_ok=True)

    order_num = normalize_order_number(material.order_num)
    files = [f for f in os.listdir(modify_dir)
        if os.path.isfile(os.path.join(modify_dir, f)) and f.endswith(('.xlsx', '.xls'))]

    modify_ops = []
    would_process_files = []

    # å…ˆæŠ“ç¾æœ‰ BOM â†’ map
    existing_bom = s.query(Bom).filter(Bom.material_id == material.id).all()
    existing_map = {str(b.material_num).strip(): b for b in existing_bom}

    for fname in files:
        path = os.path.join(modify_dir, fname)
        base_no_copy = re.sub(r'_copy_\d+', '', fname)  # èˆ‡ read_all_excel_files åŒé‚è¼¯é˜²é‡è¤‡

        already = s.query(exists().where(ProcessedFile.file_name == base_no_copy)).scalar()
        if already:
            print(f"[excelModifyTable] æª”æ¡ˆå·²è™•ç†ï¼Œç•¥éï¼š{fname}")
            continue

        # è®€ BOM sheetï¼ˆåŒ read_all_excel_files çš„æ¸…æ´—ï¼‰
        try:
            #bom_df = pd.read_excel(path, sheet_name=sheet_bom).fillna('')
            #
            bom_df = pd.read_excel(path, sheet_name=sheet_bom)
            # æ–‡æœ¬æ¬„ä½å¯è£œç©ºå­—ä¸²
            for col in ['ç‰©æ–™', 'ç‰©æ–™èªªæ˜']:
              if col in bom_df.columns:
                bom_df[col] = bom_df[col].fillna('')
            # æ•¸å€¼æ¬„ä½è½‰æ•¸å­—
            for col in ['ç‰©æ–™çŸ­ç¼º', 'éœ€æ±‚æ•¸é‡', 'é ç•™é …ç›®']:
              if col in bom_df.columns:
                bom_df[col] = pd.to_numeric(bom_df[col], errors='coerce').fillna(0).astype(int)
            #
        except Exception:
            # æŸäº›èˆŠæª”ç”¨ openpyxl å…ˆé©— sheet å­˜åœ¨
            with open(path, 'rb') as f:
                wb = openpyxl.load_workbook(filename=f, read_only=True)
                if isinstance(sheet_bom, str):
                    if sheet_bom not in wb.sheetnames:
                        print(f"[excelModifyTable] ç¼ºå°‘å·¥ä½œè¡¨ï¼š{sheet_bom}ï¼Œç•¥é {fname}")
                        continue
                else:
                    # å¦‚æœç”¨ç´¢å¼•ï¼Œé€™æ”¯åˆ†æ”¯ä¸åšï¼›ç›´æ¥ raise
                    raise
            bom_df = pd.read_excel(path, sheet_name=sheet_bom).fillna('')

        if 'è¨‚å–®' not in bom_df.columns:
            print(f"[excelModifyTable] ç¼ºå°‘ã€è¨‚å–®ã€æ¬„ï¼Œç•¥é {fname}")
            continue

        # è¨‚å–®æ¬„æ­£è¦åŒ–ï¼ˆæ¯”ç…§ read_all_excel_filesï¼‰
        bom_df.iloc[:, 0] = (
            bom_df.iloc[:, 0]
            .apply(normalize_order_number)
            .replace('nan', '')
            .astype(str)
        )

        rows = bom_df[bom_df['è¨‚å–®'] == order_num]
        if rows.empty:
            print(f"[excelModifyTable] æª”æ¡ˆ {fname} ç„¡æ­¤å–®è™Ÿ {order_num}ï¼Œç•¥é")
            continue

        # Excel(æ–°) â†’ map
        incoming_map = {}
        for _, r in rows.iterrows():
            mnum = str(clean_nan(r.get('ç‰©æ–™')) or '').strip()
            if not mnum:
                continue
            incoming_map[mnum] = {
                'seq_num':          clean_nan(r.get('é ç•™é …ç›®')),
                'material_comment': clean_nan(r.get('ç‰©æ–™èªªæ˜')) or '',
                'req_qty':          clean_nan(r.get('éœ€æ±‚æ•¸é‡')) or 0,
            }

        # remove
        for mnum, old in existing_map.items():
            if mnum not in incoming_map:
                modify_ops.append({
                    'action':      'remove',
                    'material_id': material.id,
                    'seq_num':     old.seq_num,
                    'material_num': mnum,
                })

        # add / update
        for mnum, new in incoming_map.items():
            old = existing_map.get(mnum)
            if not old:
                modify_ops.append({
                    'action':      'add',
                    'material_id': material.id,
                    'seq_num':     new['seq_num'],
                    'material_num': mnum,
                    'mtl_comment': new['material_comment'],
                    'qty':         new['req_qty'],
                    'start_date':  material.material_delivery_date,
                })
            else:
                changed = False
                old_c = str(old.material_comment or '')
                new_c = str(new['material_comment'] or '')
                if old_c != new_c:
                    changed = True
                try:
                    old_q = float(old.req_qty or 0)
                    new_q = float(new['req_qty'] or 0)
                    if old_q != new_q:
                        changed = True
                except Exception:
                    changed = True

                if changed:
                    modify_ops.append({
                        'action':          'update',
                        'material_id':     material.id,
                        'seq_num':         new['seq_num'] if new['seq_num'] is not None else old.seq_num,
                        'material_num':    mnum,
                        'mtl_comment_new': new['material_comment'],
                        'qty_new':         new['req_qty'],
                    })

        would_process_files.append((fname, path, base_no_copy, out_dir))

    return modify_ops, would_process_files


@excelTable.route('/modifyExcelFiles', methods=['POST'])
def modify_excel_files():
    print("modifyExcelFiles...")

    """
    è®€å– excel_modify å…§çš„ Excel â†’ ç”¢ç”Ÿ BOM å·®ç•° â†’ ï¼ˆé è¨­ï¼‰ç›´æ¥å¯«å…¥ DB â†’ ç§»æª”åˆ° excel_outã€‚
    åƒæ•¸ï¼š
      id / material_id: å·¥å–®ç·¨è™Ÿ
      dry_run: true å‰‡åªæ¯”å°ä¸å¯«åº«ã€ä¸ç§»æª”ï¼ˆé è¨­ Falseï¼‰
    å›å‚³ï¼š
      status, message, results(added/updated/removed), bom(æœ€æ–°), processedFiles(å¯¦éš›ç§»æª”æ¸…å–®)
    """
    payload = request.get_json(silent=True) or {}
    material_id = payload.get("material_id") or payload.get("id")
    #id = payload.get("id")
    dry_run = bool(payload.get("dry_run", False))

    print("material_id:",material_id)

    #if not material_id or not id:
    if not material_id:
        return jsonify({"status": False, "message": "ç¼ºå°‘ material_id / id"}), 400

    s = Session()
    try:
        material = s.query(Material).get(int(material_id))
        if not material:
            return jsonify({"status": False, "message": "æ‰¾ä¸åˆ°å°æ‡‰çš„ Material"}), 404

        # 1) æ”¶é›†å·®ç•°ï¼ˆä¸æ”¹ DBï¼‰
        # results:ã€Œå·®ç•°ã€æ˜ç´°ï¼Œè®“å‰ç«¯çŸ¥é“é€™æ¬¡åˆ°åº•å‹•äº†å“ªäº›è³‡æ–™
        #   results.added: Bom[]ï¼šæ–°å¢çš„ BOM åˆ—è¡¨ï¼ˆæ¯ä¸€ç­†é€šå¸¸æ˜¯ Bom.get_dict() çš„çµæœï¼‰ã€‚
        #   results.updated: (Bom | Meta)[]ï¼šæ›´æ–°éçš„ BOMã€‚è‹¥æŸç­†æ²’æœ‰ä»»ä½•è®ŠåŒ–ï¼Œæœƒå› "noop": trueï¼›è‹¥æ‰¾ä¸åˆ°å°æ‡‰èˆŠè³‡æ–™ï¼Œæœƒå› "skipped": "not_found"ã€‚
        #   results.removed: Meta[]ï¼šè¢«åˆªé™¤çš„ BOMï¼ˆé€šå¸¸åŒ…å« id / material_num / seq_num ç­‰è­˜åˆ¥æ¬„ä½ï¼‰ã€‚
        modify_ops, files_to_move = _collect_bom_diffs_from_modify_dir(s, material)
        if not modify_ops:
          return jsonify({
            "status": False,
            "message": "æ²’æœ‰å·®ç•°æˆ–æ²’æœ‰å¯è™•ç†çš„æª”æ¡ˆ(è«‹ä¸Šå‚³ä¿®æ­£å·¥å–®)",
            "results": {"added": [], "updated": [], "removed": []},
            "bom": [b.get_dict() for b in s.query(Bom).filter(Bom.material_id == material.id).all()],
            "processedFiles": []
          })

        if dry_run:
          # åƒ…æ¯”å°ï¼Œä¸å¯«åº«ã€ä¸ç§»æª”ã€ä¸è¨˜ ProcessedFile
          return jsonify({
            "status": True,
            "message": "dry_run åƒ…æ¯”å°å®Œæˆï¼Œæœªå¯«å…¥è³‡æ–™åº«ã€æœªç§»æª”",
            "diff_ops": modify_ops
          })

        # 2) å¯«å…¥ DBï¼ˆapply diffsï¼‰
        results, latest_bom = _apply_bom_diffs_tx(s, material, modify_ops)

        # 3) è¨˜éŒ„å·²è™•ç†ä¸¦ç§»æª”åˆ° excel_outï¼ˆå°¾ç¢¼ mdfï¼‰
        base_in = os.path.abspath(current_app.config['baseDir'])
        out_dir = base_in.replace("_in", "_out")
        processed = []
        for fname, path, base_no_copy, out_dir in files_to_move:
            pf = ProcessedFile(file_name=base_no_copy)
            s.add(pf)
            s.flush()

            new_name = get_unique_filename(out_dir, fname, "mdf")
            os.makedirs(out_dir, exist_ok=True)
            shutil.move(path, os.path.join(out_dir, new_name))
            processed.append(new_name)

        s.commit()

        return jsonify({
          "status": True,
          "message": "BOM å·®ç•°å·²å¥—ç”¨ä¸¦å®Œæˆç§»æª”",
          "results": results,
          "bom": latest_bom,
          "processedFiles": processed
        })

    except Exception as e:
        s.rollback()
        return jsonify({"status": False, "message": str(e)}), 500
    finally:
        try:
            s.close()
        except:
            pass

